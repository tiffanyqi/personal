<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>Engineering Progress | Tiffany Qi</title>
    <meta charset="UTF-8">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700" rel="stylesheet">
    <link href='../assets/css/blog.css' rel='stylesheet' type='text/css'>
    <script type="text/javascript" src="../assets/js/mixpanel.js"></script>
    <script>
      mixpanel.track("Project View", {"Project": "Engineering Progress"});
    </script>
  </head>

  <body>

    <div id="navbar">
      <a href="#top" class="navbar-item active">Introduction</a>
      <a href="#methodology" class="navbar-sub-item">Methodology</a>
      <a href="#dream" class="navbar-sub-item">The Dream</a>
      <a href="#data" class="navbar-item">The Data</a>
      <a href="#data-pre-post-review" class="navbar-sub-item">Pre-Review and Post-Review</a>
      <a href="#data-average-working-time" class="navbar-sub-item">Average Working Time</a>
      <a href="#data-number-of-comments" class="navbar-sub-item">Number of Comments</a>
      <a href="#data-number-of-prs" class="navbar-sub-item">Number of PRs</a>
      <a href="#data-lines-of-code" class="navbar-sub-item">Lines of Code</a>
      <a href="#findings" class="navbar-item">Findings</a>
      <a href="#conclusion" class="navbar-sub-item">Conclusion</a>
      <a href="#acknowledgements" class="navbar-sub-item">Acknowledgements</a>
    </div>

    <div class="container">
        <!-- INTRODUCTION AND METHODOLOGY -->
        <h1 id="top">A Study in Software Engineering Progress</h1>
        <div class="date">April 7, 2019</div>

        <p>
            I’ve officially been a software engineer at Mixpanel for one year! For the full year, I’ve been tracking my progress via Github and thought I’d share my results since then. You can skip the background and methodology if you wish by going directly to the <a href="#data">Data</a> or the <a href="#findings">Findings</a>.
        </p>
        <p>
            Some background: I started programming in 2014 in my junior year at UC Berkeley. While I was at school, I took a couple of courses in theory (CS 61A, CS 61B, CS 160, and CS 169), and outside of class I taught myself basic web development and worked on side projects (largely on my own). As one does when they first start out, my method of programming was to hack things together via StackOverflow until it worked.
        </p>
        <p>
            While at Mixpanel, I realized I wanted to work full time as a software engineer. In January 2018, I was the first to go through an official path to engineering, and in April 2018 I became a full fledged software engineer.
        </p>
        <p>
            I had a lot to learn as an engineer for a company, and I still do. For one, the method I used for 4 years, hacking things together until they worked, doesn’t work for people who have worked on a relatively stable and mature codebase and know how to best write software for that codebase. I had to get rid of my JQuery habit, navigate <a href="https://github.com/mixpanel/panel">Panel</a> (a Javascript framework built by Mixpanel) for our new features, and learn how to write clean code that others would approve of.
        </p>
        <p>
            To ensure I was on the right track, I wanted to track my progress, and I figured the most straightforward way to do so would be to record time spent and statistics from Github pull requests (PRs) of different projects.
        </p>

        <h3 id="methodology">Methodology</h2>
        <p>After each PR was complete, I collected the following information in a Google Spreadsheet:</p>
        <ul>
            <li><strong>Date information:</strong> month started, date started, date reviewed, and date pushed per PR</li>
            <li><strong>Time spent:</strong> hours and workdays spent on pre-review, post-review, total number of workdays, total hours worked, and the total number of hours per day</li>
            <li><strong>Ratio of pre-review vs post-review</strong></li>
            <li><strong>Differing lines of code:</strong> lines of code added minus number of lines removed, or the total lines modified</li> 
            <li><strong>Number of comments</strong></li>
            <li><strong>Project information: </strong> project number, component, title, stack, framework used</li> 
        </ul>
        <p>
            Afterwards, I synthesized the data by taking these values and aggregating them into data by period, which is categorized by my engineering level and the project working on at the time, and by month.
        </p>
        <p>
            I calculated the time spent in hours by using Google Calendar and recorded the time in which I started and stopped working on a certain PR. You can read more specifically on my method in my <a href="college-productivity">College Productivity Analysis</a>. I used a single calendar called “coding”, and each event title constituted a PR. I included the typing of code, research, and brainstorms with coworkers into the time spent calculation for each PR. I also have other calendars, such as my main calendar (scheduling events with other coworkers), and tasks (writing documentation, doing HR tasks, deploying code, code reviews, etc).
        </p>
        <img class="calendar" src="../assets/img/work/work-calendar.png" alt="March 2019, Mixpanel">
        <p>
            A typical week from March 2019.
        </p>
        <p>
            Note that one piece of information that would have been useful to include is the difficulty of a task. I have not included them here in this calculation because we don't estimate it on the task quantiatively before we begin (unlike some other companies do). Thus, since evaluating difficulty post-mortem is subjective and biased, I did not want to include it in this analysis.
        </p>
        <p>
            The following are the different periods of my engineering, the first being my level and the second being the team or project:
        </p>
        <ul>
            <li><strong>Engineering path & SRFE: </strong>20 work days, 1 month. Worked on small bug fixes before starting on my assigned task.</li>
            <li><strong>Engineering path & KEEP: </strong>38 work days, 2 months. Joined a team where each member worked on separate unrelated projects. I worked primarily in Backbone during this time.</li>
            <li><strong>L1 & KEEP: </strong>43 work days, 2.5 months. After officially becoming a software engineer, I continued on the same team. L1 is a level reserved for internal transfers.</li>
            <li><strong>L1 & D2: </strong>77 work days, 4 months. Our team transitioned to work on a single product: dashboards. I worked primarily in Panel.</li> 
            <li><strong>L2 & D2: </strong>27 work days, 2 months. I transitioned to L2 (new grad status) and continued to work on dashboards.</li> 
            <li><strong>L2 & AL: </strong>70 work days (as of 3/27/2019), 3.5 months. Our team broadened scope, and I began working on a new product. I worked again primarily in Panel and python. The screenshot of the calendar above would fit into this period of time.</li>
        </ul>

        <h3 id="dream">The Dream</h3>
        <p>
            The dream for software engineers is to get a LGTM (“looks good to me”) on a significant PR and an approval to ship from a fellow colleague, or even better, a senior engineer. This single phrase shows that they approve of your process and code quality.
        </p>
        <p>
            The following factors tracked contribute to this goal:
        </p>
        <ul>
            <li><strong>Number of comments.</strong> If I’m improving, I should have fewer comments on my PRs.</li> 
            <li><strong>Ratio between pre-review and post-review. </strong>If I’m improving, I should have a gradually higher pre-review ratio than post-review ratio.</li>
        </ul>
        <p>
            Other information that I’m interested to gather:
        </p>
        <ul>
            <li><strong>Pre-review and post-review time. </strong>How long do I spend before and after the review?</li>
            <li><strong>Average working time. </strong>How long do I spend coding? Being productive?</li> 
            <li><strong>Lines of code added. </strong>How much code do I contribute?</li>
            <li><strong>Number of PRs and their cadence. </strong>How often do I deploy code to our codebase?</li>
            <li><strong>Correlations between time, comments, and amount of code. </strong>Can I use correlations to increase my chances of getting a LGTM?</li> 
        </ul>


        <!-- DATA -->
        <h2 id="data">The Data</h2>
        <p>
            Below, I’ll go into more of the specifics of each bullet point I was interested that was contained in the methodology. The following data comes from <strong>275 workdays (14 months), 182 PRs, 8,305 lines of code added, and 1,271 comments</strong>.

        </p>

        <h3 id="data-pre-post-review">Pre-Review and Post-Review</h3>
        <p>
            Here, I’m curious to see how long I spend in each type and whether or not the amount of time I’m spending on post-review is decreasing. If so, perhaps I’m improving! I’m also interested in whether the two have any correlation.
        </p>
        <p>
            “Pre-review” is the period of time in which I spend on beginning research and coding before asking others to review, while “post-review” is that which I spend incorporating comments and feedback from others before shipping code to production. Deploy time is not added to the post-review unless I needed to revise something that came up during staging.
        </p>
        <p>
            Sometimes pre-review time also includes time redoing a PR when a reviewer lets me know that I either created the wrong feature or have to change the overall approach to account for an extra detail. In this way the wording of this section is a little misleading--my primary goal for this ratio is to determine how much time it takes to refactor or address the comments of others on coding style or existing behavior, and if I started on the wrong foot or did not include something, I don’t feel that’s completely accurate in that representation. However, I do admit that moving some PRs’ post-review time into the pre-review time fudges the numbers a bit, and thus I advise to take this section with a grain of salt.
        </p>
        <div class="graph-tall" id="prpr-graph-av-pre-and-post">
            [Average hours spent on pre-review and post-review graph]
        </div>
        <p>
            In general, you’ll see that the hours spent during pre-review has gone down from its peak of 7.05 in Eng Path/KEEP to L2/AL of 3.9, as well as for post-review from its peak of 7.8 in Eng Path/KEEP to 1.45 in L2/AL. Average workdays during the pre-review has remained steady at around 2 days, while post-review has gone down from 2.91 in Eng Path/KEEP to 0.96 in L2/AL. In addition, if we compare Eng Path/KEEP to L1/KEEP and L1/D2 to L2/D2, we’ll see that average hours and workdays decreased considerably.
        </p>
        <div class="graph-tall" id="prpr-graph-month-av-pre-and-post">
            [Average hours spent on pre-review and post-review per month graph]
        </div>
        <p>
            Here's the same graph but instead broken up in chunks of 20 workday cycles. Overall it follows the path as shown by the previous graph, except it's more obvious where the peaks are. For example, the highest post-review period that overtook the pre-review in March 2018 was during Eng Path/KEEP. A second high post-review time was in August 2018, which was during L1/D2.
        </p>
        <div class="graph-square" id="prpr-graph-pre-hours-vs-post-hours">
            [Hours of pre-review vs. hours of post-review graph]
        </div>
        <p>
            Is there a correlation between the hours of pre-review and post-review? Plotting all the data on a single graph, the coefficient of determination is 0.346, which suggests a positive moderate correlation between the two. Of course there are many outliers on this graph, such as the dot highest on post-review was a PR from Eng Path/KEEP and the one with the highest pre-review was from L1/KEEP.
        </p>
        <div class="graph-square" id="prpr-graph-no-outliers-pre-hours-vs-post-hours">
            [Hours of pre-review vs. hours of post-review graph with no outliers]
        </div>
        <p>
            Here's the same graph with the outliers removed. I define an outlier through the interquartile ratio (IQR), the traditional way of calculating outliers. If any point is outside the lower and higher boundaries of the IQR*1.5 of Q1 and Q3, it is considered an outlier. This means that I've removed any PR with a pre-review greater than 12.6 hours and a post-review of 3.75 hours.
        </p>
        <p>
            With these outliers excluded, the data is much more scattered with a coefficient of determination of 0.156. There's a weak positive correlation between pre-review and post-review hours spent on a PR.
        </p>
        <div class="graph-short" id="prpr-graph-max-hours">
            [Max hours of pre-review vs. max hours of post-review graph]
        </div>
        <p>
            These numbers represent the PR that obtained the most number of hours during pre-review and post-review for each section. Both pre-review and post-review are decreasing, albeit post-review decreasing a bit more unstably. However, if we compare Eng Path/KEEP to L1/KEEP and L1/D2 to L2/D2, max post-review hours have definitely decreased.
        </p>
        <div class="graph-short" id="prpr-graph-pre-post-ratio">
            [% Pre-Review vs. % Post-Review graph]
        </div>
        <p>
            Here’s a graph of the ratio between pre-review and post-review for every PR deployed in sequential order. If we drew a trendline for just KEEP and D2, you'd notice that the treadline trends upwards, suggesting an increasing pre-review ratio. As for AL, the line may be even, perhaps even trending downwards.
        </p>
        <div class="graph-short" id="prpr-graph-av-pre-post">
            [Average review slices graph]
        </div>
        <p>
            In terms of the ratio between pre-review and post-review, on average you’ll see that the ratio is increasing in favor of larger pre-review (58.71% in Eng Path/KEEP to 87.2% in L2/D2). Currently that number is 75.6% in L2/AL. It’s also increasing within KEEP (Eng Path to L1) and D2 (L1 to L2).
        </p>
        <div class="graph-short" id="prpr-graph-month-av-pre-post">
            [Average review slices graph by month]
        </div>
        <p>
            Here's the same graph broken up by 20 workday cycles. Here we can see a clear delineation whenever a new period or project was started. In June 2018, I began D2, and continued to rise until the start of a new project in December 2018. From there, my ratio dropped to an average of 72%, and gradually increased again to 82%. Of course the numbers within Eng Path is lowest given I first started my assign tasks.
        </p>
        <p>
            <strong>In summary: </strong>
            I spent fewer hours and workdays on both pre-review and post-review on average per PR (except post-review workdays remained steady). There is a weak positive linear correlation between the two as well. A start of a new project causes the pre-review to post-review ratio to decrease, but over time within that project it gradually increases, which does suggest an improvement.
        </p>

        <h3 id="data-average-working-time">Average Working Time</h3>
        <p>
            Here, I’m curious how long I’m spending per PR and in general, as well as whether they have any correlation. Note that items such as meetings, lunch, and non-coding projects are included in an average day but not on the “hours spent” number. Vacations and offsites are removed from the “day” number.
        </p>
        <div class="graph-tall" id="time-graph-av-hours-pr-day">
            [Average total hours worked per PR vs average hours per day spent on PR graph]
        </div>
        <p>
            I have decreased the amount of hours worked per PR on average from 14.84 in Eng Path/KEEP to 5.35 in L2/AL, and also decreased slightly the amount of workdays from 2.12 in Eng Path/KEEP to 1.81 workdays in L2/AL per PR on average.
        </p>
        <div class="graph-short" id="time-graph-av-hours-coding">
            [average hours coding per day graph]
        </div>
        <p>
            In terms of the hours spent per day on PRs, I spent the most at L2/D2 of 5.06 hours per day, while L2/AL was 3.98 hours per day. I was working 50/50 during the Eng path, which explains why the number is low on average for Eng Path/SRFE (1.23). I must have pushed myself really hard during Eng Path/KEEP (and maybe neglected other duties) to achieve an average per day of 4.24 hours! Gradually I've increased the time spent on PRs, although the time in L2/AL is below trend.
        </p>
        <div class="graph-short" id="time-graph-month-av-hours-coding">
            [average hours coding per day graph by month]
        </div>
        <p>
            Here's the same graph broken out up 20 workday cycles. Interestingly, the same logic earlier applies to here: the start of a project shows a trough in time spent coding (July and December 2018), and then gradually increases. This could also be explained by the holiday season as well.
        </p>
        <p>
            So, what did I spend my time on? I did some extra calculations and found the following:
        </p>
        <div class="graph-tall" id="time-graph-av-hours-productive">
            [average hours productive on graph]
        </div>
        <ul>
            <li><strong>Meetings: </strong>21 minutes per day (L1/D2) to 26 minutes per day (L2/AL)</li>
            <li><strong>Code reviews: </strong>5 minutes per day (L1/KEEP) to 10 minutes per day (L2/AL)</li>
            <li><strong>Deploying: </strong>I didn’t get deploy access until in between L1 and L2. I spent 25 minutes per day (L2/D2) to 26 minutes per day (L2/AL) on deploying code to production.</li>
            <li><strong>Fixing / improving devbox: </strong>During L2/D2, we were transitioning from Softlayer devboxes to GCP. I spent 25 minutes per day in L2/D2, and 14 minutes per day in L2/AL</li>
            <li><strong>Other projects: </strong>6 minutes per day (L1/D2) to 19 minutes per day (L2/AL)</li>
            <li><strong>Opslead: </strong>I’m shadowing to become opslead, which is why it’s only a small sliver in L2/AL. This number will likely grow in the upcoming months.</li>
        </ul>
        <p>
            Thus, I went from spending on average 5.16 hours per day in L1/KEEP to 6.52 hours per day in L2/D2, so overall the time I’m spending is increasing, especially through code reviews, other projects, deployment, and soon as opslead.
        </p>
        <p>
            <strong>In summary: </strong>
            the amount of time spent on PRs and per day has decreased over time, but the amount of time I’m spending on average on work activities is increasing. Again the time spent on coding initially is low when starting a new project (July 2018, December 2018), but gradually increases.
        </p>

        <h3 id="data-number-of-comments">Number of Comments</h3>
        <p>
            I think of number of comments being associated with feedback: the more comments, the more errors. Thus, if the number of comments decrease per PR, that could mean that I’m doing better.
        </p>
        <div class="graph-short" id="comments-graph-av-most-comments">
            [average comments and max comments per pr graph]
        </div>
        <p>
            It looks like both the average number of comments per PR and the most comments in a single PR is decreasing, from 22.09 in Eng Path/KEEP to 7.37 in L2/AL, and from a whopping 99 in Eng Path/KEEP to 36 in L2/AL. If we compare Eng Path/KEEP to L1/KEEP and L1/D2 to L2/D2, we’ll see that average comments are decreasing as well.
        </p>
        <div class="graph-short" id="comments-graph-month-av-comments">
            [average comments per pr graph by month]
        </div>
        <p>
            Here is the same graph broken up by 20 weekday periods. Again, it's clear that the average comments decrease within projects. Interestingly there are more comments in July and August 2018, and in AL (December 2018 to March 2019) the comments continue to increase.
        </p>
        <div class="graph-square" id="comments-graph-month-av-hours-vs-av-comments">
            [average hours worked in PR vs average comments per pr graph by month]
        </div>
        <p>
            Out of curiosity, here's the plot between the average hours worked in PR and average comments per PR broken up by 20 weekday periods. The correlation of determination is 0.682, which suggests that the data is strongly positively linearly correlated.
        </p>
        <div class="graph-square" id="comments-graph-hours-worked-vs-comments">
            [hours worked vs comments graph]
        </div>
        <p>
            I also plot the number of hours worked per PR with the number of comments to see if there is a correlation between the two. The coefficient of determination is 0.598, which does suggest somewhat of a positive linear correlation between the two. There are still outliers here, such as the dot highest on post-review that was a PR from Eng Path/KEEP and the one with the highest pre-review was from L1/KEEP.
        </p>
        <div class="graph-square" id="comments-graph-no-outliers-hours-worked-vs-comments">
            [hours worked vs comments graph without outliers]
        </div>
        <p>
            Here's the same graph with the outliers removed. I've removed any PR with total hours worked that's more than 16 hours and more than 21 comments. The coefficient of determination again has decreased to 0.363, which still suggests a bit of a positive linear correlation but definitely not as strong as with the outliers.
        </p>
        <p>
            <strong>In summary: </strong>
            the number of comments is decreasing in general and within projects, which does suggest somewhat of an improvement (except in L2/AL). The amount of time and number of comments are somewhat linearly correlated as well, but averaged by month the numbers are strongly correlated.
        </p>

        <h3 id="data-number-of-prs">Number of PRs</h3>
        <p>
            We’ll take a look at PR cadence, PR code type, and the number of large PRs.
        </p>
        <p>
            I define “large” PRs rather loosely: it must have more than 100 lines of code, but after that it’s a bit more subjective. For example, if I wrote a lot of test code to go with it, I don’t consider it a large PR. If for Javascript there’s a lot of comments or adding of a type.ts file for type checking purposes or much copy and pasting of code, I don’t consider it a large PR.
        </p>
        <div class="graph-short" id="prs-graph-percent-large-prs">
            [large prs percentage graph]
        </div>
        <p>
            In this above graph, you’ll see that the number of these large PRs have decreased over time, from 18.18% in Eng Path/KEEP to 5.77% in L2/AL.
        </p>
        <div class="graph-short" id="prs-graph-cadence">
            [pr every x day graph]
        </div>
        <p>
            In addition, the cadence of PR has decreased from a PR every 4 days in Eng Path/SRFE to a PR every 1.35 days in L2/AL.PRs are being deployed quicker.  Again, I did not receive deploy access until L1, and so that could also be the reason for longer PR times in Eng Path. This time if we compare Eng Path/KEEP to L1/KEEP and L1/D2 to L2/D2, we’ll see that the cadence lengthens slightly within projects.
        </p>
        <div class="graph-short" id="prs-graph-month-cadence">
            [pr every x day graph by month]
        </div>
        <p>
            Here's the same graph broken out up 20 workday cycles. This graph looks almost just like the comments graph, as the cadence decrease within projects but that it takes longer to deploy in July and August 2018 and in AL (December 2018 to March 2019).
        </p>
        <div class="graph-square" id="prs-graph-month-cadence-vs-comments">
            [pr every x day vs comments graph by month]
        </div>
        <p>
            Since the cadence graph and the comments graph broken up by 20 workday cycles looked so similar, I wanted to see what they look like together. The coefficient of determination is 0.259, which is considered weak. But, I'm not convinced.
        </p>
        <div class="graph-square" id="prs-graph-no-outliers-month-cadence-vs-comments">
            [pr every x day vs comments graph by month without outliers]
        </div>
        <p>
            Here's the graph again without the January 2018 data point of 1.5 comments. The coefficient of determination is 0.931, which suggests that the number of comments and the larger the PR averaged out within a month is strongly positively correlated.
        </p>
        <div class="graph-short" id="prs-graph-type">
            [prs by type graph]
        </div>
        <p>
            The type of PR could also have an influence as well. I first learned Panel in Eng Path/KEEP, which took me a while to grasp. Since then, I have had many more PRs over time, much of which is written in Panel.
        </p>
        <p>
            <strong>In summary: </strong>
            I have deployed more PRs per week and fewer large PRs over time. In addition, the cadence between PRs and the number of comments within that PR are strongly positively correlated. I've also coded more in Panel and less in Backbone.
        </p>

        <h3 id="data-lines-of-code">Lines of Code</h3>
        <p>
            And now for contribution to our code base: how much code am I adding? Generally speaking, more lines of code is more productivity. Again the calculation is the number of lines added minus the number of lines removed. I understand that this could have been the number of lines added <i>plus</i> the number of lines removed, since removed code is also considered productive (if not better than adding code), however this would mean that lines with even the most miniscule changes (such as tabs) would count as double, which I don't believe should be considered productive. Thus, I figured subtracting the two would be sufficient.
        </p>
        <div class="graph-short" id="code-graph-av-lines-code-day">
            [average lines of code added per day graph]
        </div>
        <p>
            I’m adding more code per day on average, from 15.79 in L1/KEEP to 38.26 in L2/AL. Again, during my Eng Path I worked 50/50, so this number shouldn’t be as high as the others.
        </p>
        <div class="graph-short" id="code-graph-month-av-lines-code-day">
            [average lines of code added per day graph by month]
        </div>
        <p>
            Here again is a graph of the above broken up into 20 workday cycles. Lines of code is gradually increased over time, and again during projects (June 2018 and December 2018).
        </p>
        <div class="graph-short" id="code-graph-max-lines-code-pr">
            [max lines of code added in pr graph]
        </div>
        <p>
            This graph mimics the average lines of code per day graph very closely. It could be that the few larger PRs were outliers that influenced the number lines added on average as well. 785 lines in a single PR in L1/D1?? I remember that PR being stressful from wrangling multiple features, which is why it existed. The 556 lined PR in L2/AL wasn’t as bad since it was mostly test code and written in python, while the other max PRs represented here are all written in Javascript. Overall, the max lines of code are increasing. Again, if we compare Eng Path/KEEP to L1/KEEP and L1/D2 to L2/D2, the lines of code do decrease within projects for both graphs.
        </p>
        <div class="graph-short" id="code-graph-av-lines-code-pr">
            [average different lines of code of pr graph]
        </div>
        <p>
            Again, this graph is pretty similar to the above two, most likely as a result from the larger PRs that bumped up the amount of code.
        </p>
        <div class="graph-square" id="code-graph-hours-worked-vs-code-added">
            [total hours worked vs different lines of code graph]
        </div>
        <p>
            The coefficient of determination here is 0.555, which suggests that the total hours worked per PR and the amount of lines of code added is leaning towards strongly linearly correlated. Again there are more outliers, such as the 785 lined PR that took 53.5 hours to complete from L1/D2, and the 556 lined PR took 17.25 hours to complete from L2/AL.
        </p>
        <div class="graph-square" id="code-graph-no-outliers-hours-worked-vs-code-added">
            [total hours worked per PR vs different lines of code graph no outliers]
        </div>
        <p>
            Here's the same graph with the outliers removed. Outliers are defined as the number of hours worked are above 16 and code added is fewer than -66 and more than 114. The coefficient of determination is 0.409, which suggests that the total hours worked per PR and the amount of lines of coded added are still moderately linearly correlated, but not as strong as thought.
        </p>
        <div class="graph-square" id="code-graph-code-added-vs-comments">
            [lines of code per PR vs comments per PR graph]
        </div>
        <p>
            Out of curiosity, I also plotted the lines of code with the comments per PR. The coefficient of determination is 0.211, which suggests a moderate linear correlation.
        </p>
        <div class="graph-square" id="code-graph-no-outliers-code-added-vs-comments">
            [lines of code per PR vs comments per PR graph no outliers]
        </div>
        <p>
            If we remove all the outliers, which is the lines of code fewer than -66 and more than 114 and the number of comments is above 21, the coefficient of determination is 0.175, which is even less correlated than with the outliers.
        </p>
        <p>
            <strong>In summary: </strong>
            the lines of code added are also increasing in general and in projects. There is also a moderate positive linear correlation between the number of hours worked and the lines of code added, and a much weaker correlation between amount of comments and lines of code added.
        </p>

        <!-- FINDINGS -->
        <h2 id="findings">Findings</h2>
        <p>
            <strong>Smaller PRs equal higher productivity.</strong> I shifted from containing all code into a single PR for a feature to breaking up a single feature into smaller iterative PRs. This single shift was largely responsible for a decrease in time spent per PR (pre-review, post-review, average working time), decrease in comments per PR, and increase in number of PRs deployed. Breaking PRs up into smaller chunks allows reviewers to understand a larger whole piece by piece and catch things that might have otherwise be missed on a larger PR. This is a common practice at Mixpanel and something that we encourage all of our engineers to do.
        </p>
        <p>
            <strong>I improved, probably.</strong> Comparing Eng Path data to now and within projects (KEEP and D2), it’s clear that there are fewer comments, more PRs deployed, and a higher ratio of pre-review to post-review, which does appear to be closer to the “LGTM” state. Even though L2/AL seems to show a slight lower PR deploy cadence and more comments when breaking apart by month, that doesn’t necessarily mean that I’ve taken a step back. For example, AL is a completely new project with its different set of challenges more fitting of my level than of previous projects as on the eng path or L1. However, tying in a difficulty component to each project would confirm this.
        </p>
        <p>
            <strong>Starting new projects at first will look less productive than usual. </strong> When I start a new project, within that month I average more comments per PR, less time spent, a lower pre-review ratio, and less code added to production. Perhaps this is because I'm researching or still figuring things out, which leads to PRs that have more comments and more non-PR work. However, over time when I'm in the zone or know what's going on, these numbers all trend towards the positive.
        </p>
        <p>
            <strong>I spend less time fixing my devbox than I thought.</strong> This surprised me. Our devboxes often error, and it seems like the end of the world when the normal mechanisms of rebooting them don't work. However, it looks like right now I only spend about 14 minutes per day fixing issues or improving my environment, which is about an hour per week. This is less than my predicted 2 hours per week.
        </p>
        <p>
            <strong>I spend more time deploying code than I thought.</strong> Deployment at Mixpanel involves pushing changes to staging (which can take time waiting in line to get the staging locks and running all necessary successful deployment pieces for staging), testing the change on staging, and actually deploying code (which can take more time for the whole cron to complete). And with the increase in the number of PRs deployed, so does the amount of time it takes to go through with the deployment process. I spend 26 minutes per day (2 hours per week), which is even more than fixing my devbox!
        </p>    
        <p>
            <strong>I spend on average 5.68 hours per day productively, 4.50 on PRs.</strong> The PR number has decreased lately, while the number of productive hours has increased over time. That means in a typical 8 hour day, 73.3% is spent productively, which...isn’t totally a bad number?
        </p>
        <p>
            <strong>The average cadence between PRs, average hours spent per PR, and the average number of comments per PR per month are strongly positively correlated. </strong>This implies that the larger or more complicated the PR (as it takes longer to deploy), the more comments are left, which makes sense. What's interesting is that when we look at the raw numbers rather than the averages by month, the correlations between these three factors and the hours it takes to produce are weak to moderate at best.
        </p>

        <h2 id="conclusion">Conclusion</h2>
        <p>
            I’ve learned a lot about software engineering over the past year, and there’s a lot more that I have to learn. I definitely have a long way to go before I can create a significant PR with LGTM, but for now I’m happy that I no longer have to see 99 comments on a single PR: fingers crossed.
        </p>
        <p>
            I plan to continue breaking up larger features into smaller PRs and spending more time on the pre-review stage (ensuring the methodology is correct and doing research). In addition, I should find some way to decrease the deployment time and increase the amount of productive and coding time.
        </p>
        <p>
            What do you think about this data and the conclusions I’ve presented here? I encourage all comments and look forward to an open discussion. I welcome anyone who'd like to discuss further about my results to comment and read about more feelings here.
        </p>

        <h2 id="acknowledgements">Acknowledgements</h2>
        <p>
            Thank you to my team: Jordan, Josh, and Jing, for putting up with my code and questions on a daily basis.
        </p>
        <p>
            Thank you to Bernie, Robert, and Zak for believing in me and giving me the flexibility to pursue my own path.
        </p>
        <p>
            Thank you to James for your inspiring words on logging time in calendars and productivity, which I use religiously to this day.
        </p>
        <p>
            Thank you to Aria for planting the idea of programming in my head.
        </p>
        <p>
            Thank you to Max, who started my first side project and taught me all about Django and Javascript web development.
        </p>
        <p>
            Thank you to Andrew for encouraging me to continue to code and to never give up.
        </p>
        <p>
            Thank you to everyone who read and shared <a href="https://hackernoon.com/a-college-students-individual-analysis-of-productivity-of-four-years-e51e5ec3af6">“A college student’s individual analysis of productivity of four years”</a> I wrote in 2016, which gave me the confidence to continue to create crazy projects like this.
        </p>
        <p>
            Thank you to my parents for putting up with me and supporting my switch to software engineering even though it has nothing to do with my major. You are the best.
        </p>

    </div>


  <!-- JAVASCRIPT TO MAKE THIS WORK -->
    <script type="text/javascript" src='https://www.gstatic.com/charts/loader.js'></script>
    <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <script type="text/javascript" src="../assets/js/graphs.js"></script>
    <script type="text/javascript" src="../assets/js/blog.js"></script>
    <script type="text/javascript">
        google.charts.load('current');
        const MONTH_DATA_URL = 'https://docs.google.com/spreadsheets/d/1snVaG2XNltJHeJpsBj6ugGoX8Y-3xpqSNIBXdedl_Yg/edit#gid=374449975';
        const RAW_DATA_URL = 'https://docs.google.com/spreadsheets/d/1PtHdOUadiaUj5RuRNTUY8912LzDZBlODD9jr7U7QAgI/edit#gid=0';
        const SUMMARY_DATA_URL = 'https://docs.google.com/spreadsheets/d/1UWoxJr9I7AWL3IOlXJunp6DPnr9vA5QyZkbuEVSOhdk/edit#gid=34086219';

        const GRAPH_FUNCTIONS = [
            drawAvTimeOnPreReviewPostReview,
            drawAvTimeOnPreReviewPostReviewMonth,
            drawMaxHoursPreReviewPostReview,
            drawHoursPreReviewVsPostReview,
            drawHoursPreReviewVsPostReviewNoOutliers,
            drawPreReviewPostReviewRatio,
            drawAveragePreReviewPostReview,
            drawAveragePreReviewPostReviewMonth,

            drawAvHoursPerPRAvHoursPerDay,
            drawAvHoursCodingPerDay,
            drawAvHoursCodingPerDayMonth,
            drawAvHoursProductivePerDay,

            drawHoursWorkedVsComments,
            drawHoursWorkedVsCommentsNoOutliers,
            drawAvCommentsMostComments,
            drawAvCommentsMonth,
            drawAvHoursVsAvCommentsMonth,

            drawPercentLargePRs,
            drawPRCadence,
            drawPRCadenceMonth,
            drawPRCadenceVsComments,
            drawPRCadenceVsCommentsNoOutliers,
            drawPRType,

            drawAvLinesCodeInPR,
            drawAvLinesCodePerDay,
            drawAvLinesCodePerDayMonth,
            drawMaxLinesCodeInPR,
            drawHoursWorkedVsCode,
            drawHoursWorkedVsCodeNoOutliers,
            drawCodeVsComments,
            drawCodeVsCommentsNoOutliers,
        ];
        GRAPH_FUNCTIONS.forEach(f => google.charts.setOnLoadCallback(f));

        // PRE-REVIEW AND POST-REVIEW
        function drawAvTimeOnPreReviewPostReview() {
            drawColumnChart({
                containerId: 'prpr-graph-av-pre-and-post',
                query: 'SELECT A,B,C,D,E',
                title: 'Average Hours Spent on Pre-Review and Post-Review',
                url: SUMMARY_DATA_URL,
                vAxisTitle: 'Hours',
            });
        }
        function drawAvTimeOnPreReviewPostReviewMonth() {
            drawLineChart({
                containerId: 'prpr-graph-month-av-pre-and-post',
                query: 'SELECT A,C,D,E,F',
                title: 'Average Hours Spent on Pre-Review and Post-Review by Month',
                url: MONTH_DATA_URL,
                vAxisTitle: 'Hours',
            });
        }
        function drawMaxHoursPreReviewPostReview() {
            drawColumnChart({
                containerId: 'prpr-graph-max-hours',
                isStacked: 'false',
                query: 'SELECT A,F,G',
                title: 'Max Hours of Pre-Review and Post-Review in PR',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawHoursPreReviewVsPostReview() {
            drawScatterChart({
                containerId: 'prpr-graph-pre-hours-vs-post-hours',
                query: 'SELECT C,D',
                title: 'Hours of Pre-Review vs Hours of Post-Review per PR',
                url: RAW_DATA_URL,
            });
        };
        function drawHoursPreReviewVsPostReviewNoOutliers() {
            drawScatterChart({
                containerId: 'prpr-graph-no-outliers-pre-hours-vs-post-hours',
                query: 'SELECT C,D WHERE C < 12.625 AND D < 3.75',
                title: 'Hours of Pre-Review vs Hours of Post-Review per PR without Outliers',
                url: RAW_DATA_URL,
            });
        };
        function drawPreReviewPostReviewRatio() {
            drawAreaChart({
                containerId: 'prpr-graph-pre-post-ratio',
                isStacked: 'percent',
                query: 'SELECT B,E,F',
                title: 'Pre-Review vs Post-Review Ratio Change Over Time',
                url: RAW_DATA_URL,
            });
        }
        function drawAveragePreReviewPostReview() {
            drawColumnChart({
                containerId: 'prpr-graph-av-pre-post',
                isStacked: 'true',
                query: 'SELECT A,H,I',
                title: 'Average Pre-Review and Post-Review Hours',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawAveragePreReviewPostReviewMonth() {
            drawAreaChart({
                containerId: 'prpr-graph-month-av-pre-post',
                isStacked: 'true',
                query: 'SELECT A,G,H',
                title: 'Average Pre-Review and Post-Review Hours by Month',
                url: MONTH_DATA_URL,
            });
        };

        // WORKING TIME
        function drawAvHoursPerPRAvHoursPerDay() {
            drawColumnChart({
                containerId: 'time-graph-av-hours-pr-day',
                query: 'SELECT A,L,M',
                title: 'Average Total Hours Worked on PR and Average Hours Spent Per Day on PR',
                url: SUMMARY_DATA_URL,
            });
        }
        function drawAvHoursCodingPerDay() {
            drawColumnChart({
                containerId: 'time-graph-av-hours-coding',
                isStacked: 'false',
                query: 'SELECT A,N',
                showLegend: false,
                title: 'Average Hours Spent on PRs per Day',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawAvHoursCodingPerDayMonth() {
            drawLineChart({
                containerId: 'time-graph-month-av-hours-coding',
                query: 'SELECT A,R',
                showLegend: false,
                title: 'Average Hours Spent on PRs per Day by Month',
                url: MONTH_DATA_URL,
            });
        };
        function drawAvHoursProductivePerDay() {
            drawColumnChart({
                containerId: 'time-graph-av-hours-productive',
                isStacked: 'true',
                query: 'SELECT A,O,P,Q,R,S,T,U',
                title: 'Average Hours Spent on Productive Work Per Day',
                url: SUMMARY_DATA_URL,
            });
        };

        // COMMENTS
        function drawHoursWorkedVsComments() {
            drawScatterChart({
                containerId: 'comments-graph-hours-worked-vs-comments',
                query: 'SELECT H,K',
                title: 'Hours of Worked per PR vs Comments per PR',
                url: RAW_DATA_URL,
            });
        }
        function drawHoursWorkedVsCommentsNoOutliers() {
            drawScatterChart({
                containerId: 'comments-graph-no-outliers-hours-worked-vs-comments',
                query: 'SELECT H,K WHERE H < 16 and K < 21',
                title: 'Hours of Worked per PR vs Comments per PR without Outliers',
                url: RAW_DATA_URL,
            });
        }
        function drawAvCommentsMostComments() {
            drawColumnChart({
                containerId: 'comments-graph-av-most-comments',
                isStacked: 'false',
                query: 'SELECT A,V,W',
                title: 'Average Comments per PR and Most Comments in PR',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawAvCommentsMonth() {
            drawLineChart({
                containerId: 'comments-graph-month-av-comments',
                query: 'SELECT A,M',
                showLegend: false,
                title: 'Average Comments in PR by Month',
                url: MONTH_DATA_URL,
            });
        };
        function drawAvHoursVsAvCommentsMonth() {
            drawScatterChart({
                containerId: 'comments-graph-month-av-hours-vs-av-comments',
                query: 'SELECT J,M',
                title: 'Average Hours Worked vs Average Comments by Month',
                url: MONTH_DATA_URL,
            });
        };

        // NUMBER OF PRS
        function drawPercentLargePRs() {
            drawColumnChart({
                containerId: 'prs-graph-percent-large-prs',
                query: 'SELECT A,X',
                showLegend: false,
                title: 'Percentage of Large PRs',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawPRCadence() {
            drawColumnChart({
                containerId: 'prs-graph-cadence',
                query: 'SELECT A,Y',
                showLegend: false,
                title: 'PR Every X Day',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawPRCadenceMonth() {
            drawLineChart({
                containerId: 'prs-graph-month-cadence',
                query: 'SELECT A,P',
                showLegend: false,
                title: 'PR Every X Day by Month',
                url: MONTH_DATA_URL,
            });
        };
        function drawPRCadenceVsComments() {
            drawScatterChart({
                containerId: 'prs-graph-month-cadence-vs-comments',
                query: 'SELECT P,M',
                title: 'PR Every X Day vs Comments by Month',
                url: MONTH_DATA_URL,
            });
        };
        function drawPRCadenceVsCommentsNoOutliers() {
            drawScatterChart({
                containerId: 'prs-graph-no-outliers-month-cadence-vs-comments',
                query: 'SELECT P,M WHERE M > 1.5',
                title: 'PR Every X Day vs Comments by Month without Outliers',
                url: MONTH_DATA_URL,
            });
        };
        function drawPRType() {
            drawColumnChart({
                containerId: 'prs-graph-type',
                isStacked: 'true',
                query: 'SELECT A,Z,AA,AB',
                title: 'PR Types',
                url: SUMMARY_DATA_URL,
            });
        };

        // CODE ADDED
        function drawAvLinesCodePerDay() {
            drawColumnChart({
                containerId: 'code-graph-av-lines-code-day',
                query: 'SELECT A,AC',
                showLegend: false,
                title: 'Average Lines of Code Added per Day',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawAvLinesCodePerDayMonth() {
            drawLineChart({
                containerId: 'code-graph-month-av-lines-code-day',
                query: 'SELECT A,O',
                showLegend: false,
                title: 'Average Lines of Code Added per Day by Month',
                url: MONTH_DATA_URL,
            });
        };
        function drawMaxLinesCodeInPR() {
            drawColumnChart({
                containerId: 'code-graph-max-lines-code-pr',
                query: 'SELECT A,AD',
                showLegend: false,
                title: 'Max Lines of Code Added in a PR',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawAvLinesCodeInPR() {
            drawColumnChart({
                containerId: 'code-graph-av-lines-code-pr',
                query: 'SELECT A,AE',
                showLegend: false,
                title: 'Average Different Lines of Code in PR',
                url: SUMMARY_DATA_URL,
            });
        };
        function drawHoursWorkedVsCode() {
            drawScatterChart({
                containerId: 'code-graph-hours-worked-vs-code-added',
                query: 'SELECT H,J',
                title: 'Hours of Worked per PR vs Code Added per PR',
                url: RAW_DATA_URL,
            });
        }
        function drawHoursWorkedVsCodeNoOutliers() {
            drawScatterChart({
                containerId: 'code-graph-no-outliers-hours-worked-vs-code-added',
                query: 'SELECT H,J WHERE H < 16 AND J < 114 AND J > -66',
                title: 'Hours of Worked per PR vs Code Added per PR',
                url: RAW_DATA_URL,
            });
        }
        function drawCodeVsComments() {
            drawScatterChart({
                containerId: 'code-graph-code-added-vs-comments',
                query: 'SELECT J,K',
                title: 'Code Added per PR vs Comments',
                url: RAW_DATA_URL,
            });
        }
        function drawCodeVsCommentsNoOutliers() {
            drawScatterChart({
                containerId: 'code-graph-no-outliers-code-added-vs-comments',
                query: 'SELECT J,K WHERE J < 114 AND J > -66 AND K < 21',
                title: 'Code Added per PR vs Comments',
                url: RAW_DATA_URL,
            });
        }
    </script>
  </body>
</html>
